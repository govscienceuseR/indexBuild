% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/extractWorks.R
\name{extractWorks}
\alias{extractWorks}
\title{Extract works associated with a concept in openAlex and store data as a compressed R list object}
\usage{
extractWorks(
  data_style = c("bare_bones", "citation", "comprehensive", "all"),
  dest_file = NULL,
  override = 1e+06,
  batch_size = 50000,
  mailto = NULL,
  concept_id = NULL,
  concept_page = NULL,
  source_id = NULL,
  source_page = NULL,
  cursor = T,
  per_page = NULL,
  to_date = NULL,
  from_date = NULL,
  keep_paratext = FALSE,
  debug = FALSE,
  sleep_time = 0.1,
  parallel = 1,
  return_to_workspace = T
)
}
\arguments{
\item{data_style}{options for how much/how little data to return, see @details}

\item{dest_file}{location to save output as a json.gz}

\item{override}{override 1M query result limit?}

\item{batch_size}{how large to chunk up into subfiles?, defaults to 50e3}

\item{mailto}{email address of user, needed to get in 'polite pool' of API}

\item{concept_id}{string for openAlex concept ID}

\item{concept_page}{string for openAlex concept page url}

\item{source_id}{(optional) openAlex ID# for the source associated with the work(s)}

\item{source_page}{(optional) openAlex webpage for the source}

\item{cursor}{boolean if TRUE will perform cursor pagination needed for iterating}

\item{per_page}{how many works returned per page}

\item{to_date}{latest publication date, in YYYY-MM-DD format or a YEAR (assumes YEAR/12/31)}

\item{from_date}{earliest publication date, in YYYY-MM-DD format a YEAR (assumes YEAR/01/01)}

\item{keep_paratext}{boolean to retain or exclude paratext from returns}

\item{debug}{boolean, if TRUE returns query url, if FALSE actually does query}

\item{sleep_time}{time to Sys.sleep() in between cursor iterations}

\item{parallel}{defaults to 1, sets cluster value in pblapply for processing works in parallel. may provide speed-ups for large lists.}

\item{return_to_workspace}{boolean for whether final result should be returned as workspace object}

\item{subdivision}{numeric value, defaults to 100k. If number returned is over this value, saves subsets of this return in 50k increments as \verb{[ID]_[increment].rds}}

\item{exit_if_over}{integer value -- abort if you find more than this number of works}
}
\description{
Primary use is to extract works associated with a given journal (source) or concept. Because the OpenAlex API limits returns to 200, this function iterates to grab all works returned by the query. Each return is a list or 200 works, to which the processWork() function is applied to iteratively develop a flat file.
}
\details{
Note that because extracted records can be pretty large--and are complicated, nested json file--there is an optional "data_style" command that lets the user specify what to return. Currently there are three options: (1) bare_bones returns OpenAlex ID + DOI, basically, results that can be used to look up the work again; (2) citation returns typical citation information, like journal name, author, etc., with a couple bonus items like source.id to link back to openAlex (3) comprehensive returns author institutional affiliations, open access info, funding data, etc.; and (4) all returns the entire result in original json format.
}
\examples{
# concept usage of extractWorks()
id <- queryConcepts('public administration')
extractWorks(concept_id = id$id,from_date = 2020,to_date = 2021,cursor = F,data_style = 'citation',per_page = 10)
# journal (source) usage of extractWorks()
id <- querySources(source = 'Journal of Public Administration Research and Theory')
extractWorks(source_id =id$results[[1]]$id,cursor = F,data_style = 'citation',per_page = 10)


}
